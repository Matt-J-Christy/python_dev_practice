{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping and Writing to Google Sheets\n",
    "    1. Get the data and parse with requests, lxml and Beatiful Soup \n",
    "    2. Data wrange into dictionaries \n",
    "    3. Create Pandas DF and clean the data\n",
    "    4. Write to Google Sheets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading scraping packages and getting pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get \n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing google sheets writing packages and declaring credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import gspread \n",
    "#Service client credential from oauth2client\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "# Print nicely\n",
    "import pprint\n",
    "#Create scope\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "#create some credential using that scope and content of startup_funding.json\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('quickstart/g_sheet_creds.json',scope)\n",
    "#create gspread authorize using that credential\n",
    "client = gspread.authorize(creds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating list of URLs for scraping and writing, and loading helper function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [passing, recieving, rushing]\n",
    "source_urls = ['http://pfref.com/tiny/WZEUG', 'http://pfref.com/tiny/LsMhB', 'http://pfref.com/tiny/Nik5u']\n",
    "\n",
    "sheet_names = ['passing', 'recieving', 'rushing']\n",
    "\n",
    "my_email = 'matthewjchristy66@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load scrape_fcn2.py \n",
    "\n",
    "def scraper(page_url, sheet_name, share_mail): \n",
    "    \n",
    "    my_header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}\n",
    "    \n",
    "    #grabbing the HTML and getting text \n",
    "    fantasy_page = get(page_url, headers = my_header)\n",
    "\n",
    "    doc = lh.fromstring(fantasy_page.content)\n",
    "    \n",
    "    print(fantasy_page)\n",
    "    \n",
    "    #parsing table elements in the HTML inside the pattern \"//tr\" --> this is a table element \n",
    "\n",
    "    table_elements = doc.xpath('//tr')\n",
    "    \n",
    "    #creating an empty array to insert the table elements \n",
    "    cols = []\n",
    "    i = 0 #setting the increment \n",
    "\n",
    "    for t in table_elements[1]:\n",
    "        i+1\n",
    "        name = t.text_content() #getting the column name from the HTML table \n",
    "        #print('%d:\"%s\"'% (i, name))\n",
    "        cols.append((name, [])); \n",
    "        \n",
    "        #Since out first row is the header, data is stored on the second row onwards\n",
    "\n",
    "    for j in range(1,len(table_elements)):\n",
    "        #T is our j'th row\n",
    "        T=table_elements[j]\n",
    "\n",
    "        #If row is not of size 24, the //tr data is not from our table \n",
    "        if len(T)!=len(table_elements[1]):\n",
    "            break\n",
    "\n",
    "        #i is the index of our column\n",
    "        i=0\n",
    "\n",
    "        #Iterate through each element of the row\n",
    "        for t in T.iterchildren():\n",
    "            data=t.text_content() \n",
    "\n",
    "            #Append the data to the empty list of the i'th column\n",
    "            cols[i][1].append(data)\n",
    "            #Increment i for the next column\n",
    "            i+=1\n",
    "        \n",
    "    #creating a dictionary for the columns in the parsed table \n",
    "    Dict={title:column for (title,column) in cols}\n",
    "\n",
    "    df=pd.DataFrame(Dict)\n",
    "    \n",
    "    #data cleaning \n",
    "    df = df.drop(df.loc[df[\"Rk\"] == 'Rk'].index)\n",
    "    df = df.drop('', 1)\n",
    "    \n",
    "    #Grapping Parameters for looping \n",
    "    n_rows = df.shape[0]\n",
    "    n_cols = df.shape[1]\n",
    "    \n",
    "    #writing to google sheets \n",
    "    import time \n",
    "\n",
    "    #Now will can access our google sheets we call client.open on StartupName\n",
    "    sheet = client.create(sheet_name) #2019-q4_fantasy-web-scraping/passing\n",
    "\n",
    "    sh.share(my_mail,  perm_type='user', role='writer') #sharing my email \n",
    "    \n",
    "    #writing data to the worksheet\n",
    "    ws = sheet.get_worksheet(0)\n",
    "\n",
    "    shaped_data = df.transpose()\n",
    "\n",
    "    ws.insert_row(df.columns.tolist(), 1)\n",
    "\n",
    "    for i in range(1, n_rows+1): \n",
    "        row = df.iloc[i-1].tolist()\n",
    "        index = i+1\n",
    "        if i%10 == 0: #printing the step in the loop\n",
    "            print(i)  \n",
    "            time.sleep(15)\n",
    "            \n",
    "        ws.insert_row(row, index) #writing the data \n",
    "    \n",
    "    print('row ', i, ' end of file')\n",
    "    time.sleep(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping throught the pages and writing to google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "10\n",
      "20\n",
      "30\n",
      "row 36  end of file\n",
      "http://pfref.com/tiny/WZEUG url 1\n",
      "<Response [200]>\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "{\n  \"error\": {\n    \"code\": 429,\n    \"message\": \"Quota exceeded for quota group 'WriteGroup' and limit 'Write requests per user per 100 seconds' of service 'sheets.googleapis.com' for consumer 'project_number:686366856477'.\",\n    \"status\": \"RESOURCE_EXHAUSTED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n        \"links\": [\n          {\n            \"description\": \"Google developer console API key\",\n            \"url\": \"https://console.developers.google.com/project/686366856477/apiui/credential\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5c3576ae2fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mscraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'url'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-8e651cc7ff2e>\u001b[0m in \u001b[0;36mscraper\u001b[1;34m(page_url, target_url)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#writing the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'row'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' end of file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\gspread\\models.py\u001b[0m in \u001b[0;36minsert_row\u001b[1;34m(self, values, index, value_input_option)\u001b[0m\n\u001b[0;32m    934\u001b[0m             },\n\u001b[0;32m    935\u001b[0m             body={\n\u001b[1;32m--> 936\u001b[1;33m                 \u001b[1;34m'values'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m             }\n\u001b[0;32m    938\u001b[0m         )\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\gspread\\models.py\u001b[0m in \u001b[0;36mvalues_update\u001b[1;34m(self, range, params, body)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m    175\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSPREADSHEET_VALUES_URL\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'put'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\gspread\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlist_spreadsheet_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIError\u001b[0m: {\n  \"error\": {\n    \"code\": 429,\n    \"message\": \"Quota exceeded for quota group 'WriteGroup' and limit 'Write requests per user per 100 seconds' of service 'sheets.googleapis.com' for consumer 'project_number:686366856477'.\",\n    \"status\": \"RESOURCE_EXHAUSTED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n        \"links\": [\n          {\n            \"description\": \"Google developer console API key\",\n            \"url\": \"https://console.developers.google.com/project/686366856477/apiui/credential\"\n          }\n        ]\n      }\n    ]\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "for j in range(0,len(source_urls)):\n",
    "\n",
    "    scraper(page_url = source_urls[j], sheet_name = sheet_name[j], share_mail = my_email)\n",
    "    \n",
    "    print(source_urls[j], 'url', j+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
