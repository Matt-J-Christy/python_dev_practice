{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Scraping and Writing into two steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get \n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting source urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://www.nfl.com/stats/weeklyleaders'\n",
    "\n",
    "weeks = [x for x in range(1,18)]\n",
    "\n",
    "stat_cat = ['Passing', 'Rushing', 'Receiving']\n",
    "\n",
    "urls = []\n",
    "\n",
    "names =[]\n",
    "\n",
    "for i in weeks:\n",
    "    for j in stat_cat:\n",
    "        full_url = base_url + '?week=' + str(i) + '&season=2019' + '&showCategory=' + j\n",
    "        urls.append(full_url)\n",
    "        name = '2019_' + 'week_' + str(i) + '_' + j\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    #grabbing the HTML and getting text \n",
    "    my_header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}\n",
    "    fantasy_page = get(url, headers = my_header)\n",
    "    \n",
    "    return(fantasy_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers(html):\n",
    "    \n",
    "    doc = lh.fromstring(html.content)\n",
    "    \n",
    "    #getting column names \n",
    "    title = doc.xpath('//tr//th')\n",
    "    \n",
    "    colnames = []\n",
    "\n",
    "    n = len(title)\n",
    "\n",
    "    for i in range(0, n):\n",
    "        name = title[i].text_content()\n",
    "        colnames.append(name)\n",
    "    \n",
    "    return(colnames)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_data(html, colnames):\n",
    "     \n",
    "    #parsing table elements in the HTML inside the pattern \"//tr\" --> this is a table element \n",
    "    doc = lh.fromstring(html.content)\n",
    "    table_elements = doc.xpath('//tr')\n",
    "    \n",
    "    #creating an empty array to insert the table elements \n",
    "    cols = []\n",
    "\n",
    "    for j in range(0, len(colnames)):\n",
    "        name = colnames[j] #getting the column name from the HTML table \n",
    "        #print('%d:\"%s\"'% (i, name))\n",
    "        cols.append((name, []))\n",
    "\n",
    "   #Since out first row is the header, data is stored on the second row onwards\n",
    "\n",
    "    for j in range(1,len(table_elements)):\n",
    "        #T is our j'th row\n",
    "        T=table_elements[j]\n",
    "\n",
    "        #If row is not of size 24, the //tr data is not from our table \n",
    "        if len(T)!=len(colnames):\n",
    "            break\n",
    "\n",
    "        #i is the index of our column\n",
    "        i=0\n",
    "\n",
    "        #Iterate through each element of the row\n",
    "        for t in T.iterchildren():\n",
    "            data=t.text_content() \n",
    "\n",
    "            #Append the data to the empty list of the i'th column\n",
    "            cols[i][1].append(data)\n",
    "            #Increment i for the next column\n",
    "            i+=1\n",
    "    return(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(cols):\n",
    "    #creating a dictionary for the columns in the parsed table \n",
    "    Dict={title:column for (title,column) in cols}\n",
    "\n",
    "    df=pd.DataFrame(Dict)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, page_url):\n",
    "    #data cleaning \n",
    "    escapes = ''.join([chr(char) for char in range(1, 32)])\n",
    "    translator = str.maketrans('', '', escapes)\n",
    "    df.columns = df.columns.str.translate(translator)\n",
    "    \n",
    "    #fixing escape charaters\n",
    "    fixed = ['Name', 'Team', 'Opp', 'Score']\n",
    "    for i in fixed:\n",
    "        df.loc[:, i] = df.loc[:, i].astype(str).str.translate(translator)\n",
    "    import re \n",
    "    week = re.search('week=(.*)&season', urls[0]).group(1)\n",
    "     \n",
    "    df.insert(1, 'Week', week)\n",
    "       \n",
    "    #returning the df\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer(data, sheet_name, share_email):\n",
    "    #Grabbing Parameters for looping \n",
    "    n_rows = data.shape[0]\n",
    "    n_cols = data.shape[1]\n",
    "    \n",
    "    #creating sheets\n",
    "     #Now will can access our google sheets we call client.open on StartupName\n",
    "    sheet = client.create(sheet_name) \n",
    "    sheet.share(share_email,  perm_type='user', role='writer') #sharing my email \n",
    "    \n",
    "    #getting cell list to batch update\n",
    "    import string\n",
    "    end_col = string.ascii_uppercase[n_cols - 1]\n",
    "    end_row = n_rows + 1\n",
    "    \n",
    "    sheet_range = 'A1:'+ end_col + str(end_row)\n",
    "    \n",
    "    #turning df to one long list \n",
    "    df_as_list = data.stack().tolist()\n",
    "    df_as_list = data.columns.tolist() + df_as_list\n",
    "    \n",
    "    #getting the target sheet \n",
    "    ws = sheet.get_worksheet(0)\n",
    "    cell_list = ws.range(sheet_range)\n",
    "    \n",
    "    #writing df list to cell range list \n",
    "    for i in range(0, len(cell_list)):\n",
    "        cell_list[i].value = df_as_list[i]\n",
    "        \n",
    "    #batch updating \n",
    "    ws.update_cells(cell_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through URLs to create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making empty dataframes\n",
    "passing = pd.DataFrame()\n",
    "receiving = pd.DataFrame()\n",
    "rushing = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(urls)): \n",
    "    source_html = get_url(urls[i])\n",
    "    colnames = get_headers(source_html)\n",
    "    table_data = get_table_data(source_html, colnames)\n",
    "    raw_df = create_df(table_data)\n",
    "    df = clean_df(raw_df, urls[i])\n",
    "    \n",
    "    if 'Passing' in urls[i]: \n",
    "        passing = pd.concat([passing, df])\n",
    "    \n",
    "    elif 'Receiving' in urls[i]: \n",
    "        receiving = pd.concat([receiving, df])\n",
    "        \n",
    "    else: \n",
    "        rushing = pd.concat([rushing, df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing (621, 13)\n",
      "Receiving (4101, 10)\n",
      "Rushing (2061, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Passing', passing.shape)\n",
    "\n",
    "print('Receiving', receiving.shape)\n",
    "\n",
    "print('Rushing', rushing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import gspread \n",
    "#Service client credential from oauth2client\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "# Print nicely\n",
    "import pprint\n",
    "#Create scope\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "#create some credential using that scope and content of startup_funding.json\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('../quickstart/g_sheet_creds.json',scope)\n",
    "#create gspread authorize using that credential\n",
    "client = gspread.authorize(creds)\n",
    "my_email = 'matthewjchristy66@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer(data = passing, sheet_name = 'passing', share_email = my_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer(data = receiving, sheet_name = 'receiving', share_email = my_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer(data = rushing, sheet_name =  'rushing', share_email = my_email)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
